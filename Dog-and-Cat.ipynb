{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnjtpeXUlsR7PyVaGd9rhm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindra-singh0507/Dog-and-Cat-implementation/blob/main/Dog-and-Cat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EH_JH7PUfIWg",
        "outputId": "045194f6-34e0-4e4e-b357-512000d12ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.21)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UZ6LKxIegbrg",
        "outputId": "cef446cb-da2a-4562-e6c5-a4308475c4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "mp0YtHVUf5Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Dw7w_QtOgLLj",
        "outputId": "300e5a1d-8463-482e-bc9b-2648033e705c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.17.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1- Data PreProcessing"
      ],
      "metadata": {
        "id": "NhNrtUxtvrlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(r'kaggle cats and dogs_5340.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(r'path_to_destination')\n"
      ],
      "metadata": {
        "id": "2O7DWB5nkprb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = r\"path_to_destination\\PetImages\"\n"
      ],
      "metadata": {
        "id": "EqR5AemWlHo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "train_path = r\"path_to_destination/PetImages\"\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbBCc0kgg55j",
        "outputId": "2e83596b-1086-4a74-c234-df3b5df2ca93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_set= test_datagen.flow_from_directory('path_to_destination/PetImages',target_size=(64,64),batch_size=32,class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLopgJ5LmHfN",
        "outputId": "67d0e49d-a9b5-41fc-c7d6-b90e59aae7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Building the CNN"
      ],
      "metadata": {
        "id": "Bb1MNv6soEdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialising the CNN"
      ],
      "metadata": {
        "id": "BBV7Kjznobl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn=tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "yrPxJLeToDJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 1: convoltion"
      ],
      "metadata": {
        "id": "IB2roGCzofP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMb8ghcEoi86",
        "outputId": "36988f14-36cd-49c0-e29c-4694d2199378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 2: pooling"
      ],
      "metadata": {
        "id": "7ySf3IF0ojex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "gAsSpKmOptPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a second convolutional layer"
      ],
      "metadata": {
        "id": "lIaNDD9womaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "JGwsmXuToswe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "flattening"
      ],
      "metadata": {
        "id": "GRhY2xJeotTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "P-3VJp4Eoum9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 4: full connection"
      ],
      "metadata": {
        "id": "5l8u5Ihfp4eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "lKgmO-M0p3po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output layer"
      ],
      "metadata": {
        "id": "JRnwMyYUp8ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "L7hGgMfjp-T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3- Training the CNN"
      ],
      "metadata": {
        "id": "HWVFSS8-rLrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "compliling the CNN"
      ],
      "metadata": {
        "id": "aBRQaD0TrPas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "W6--i6x5rS-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the CNN on the Training set and evaluating it on the Test set"
      ],
      "metadata": {
        "id": "bTQH-uHVrbxD"
      }
    },
    {
      "source": [
        "import os\n",
        "from PIL import UnidentifiedImageError\n",
        "\n",
        "def load_image_safe(image_path):\n",
        "  \"\"\"Loads an image and handles potential errors.\"\"\"\n",
        "  try:\n",
        "    img = tf.keras.utils.load_img(image_path, target_size=(64, 64))\n",
        "    return img\n",
        "  except UnidentifiedImageError as e:\n",
        "    print(f\"Error loading image: {image_path}\")\n",
        "    print(e)\n",
        "    return None\n",
        "\n",
        "def generate_data(directory, target_size=(64, 64), batch_size=32, class_mode='binary'):\n",
        "  \"\"\"Generates image data with error handling.\"\"\"\n",
        "  image_paths = []\n",
        "  labels = []\n",
        "\n",
        "  for class_name in os.listdir(directory):\n",
        "    class_path = os.path.join(directory, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "      for filename in os.listdir(class_path):\n",
        "        image_path = os.path.join(class_path, filename)\n",
        "        img = load_image_safe(image_path)\n",
        "        if img is not None:\n",
        "          image_paths.append(image_path)\n",
        "          labels.append(class_name)\n",
        "\n",
        "  datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "  return datagen.flow_from_dataframe(\n",
        "      pd.DataFrame({'filename': image_paths, 'class': labels}),\n",
        "      x_col='filename',\n",
        "      y_col='class',\n",
        "      target_size=target_size,\n",
        "      batch_size=batch_size,\n",
        "      class_mode=class_mode\n",
        "  )\n",
        "!pip install pandas\n",
        "import pandas as pd\n",
        "training_set = generate_data(train_path)\n",
        "test_set = generate_data('path_to_destination/PetImages')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ft3dE-jKsOM9",
        "outputId": "63d66b1b-30d4-42b2-b44b-7dc868eecf10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Error loading image: path_to_destination/PetImages/Dog/Thumbs.db\n",
            "cannot identify image file <_io.BytesIO object at 0x7f885a78c5e0>\n",
            "Error loading image: path_to_destination/PetImages/Dog/11702.jpg\n",
            "cannot identify image file <_io.BytesIO object at 0x7f88617f5580>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image: path_to_destination/PetImages/Cat/Thumbs.db\n",
            "cannot identify image file <_io.BytesIO object at 0x7f88617f5580>\n",
            "Error loading image: path_to_destination/PetImages/Cat/666.jpg\n",
            "cannot identify image file <_io.BytesIO object at 0x7f88611bc5e0>\n",
            "Found 24998 validated image filenames belonging to 2 classes.\n",
            "Error loading image: path_to_destination/PetImages/Dog/Thumbs.db\n",
            "cannot identify image file <_io.BytesIO object at 0x7f885a78c5e0>\n",
            "Error loading image: path_to_destination/PetImages/Dog/11702.jpg\n",
            "cannot identify image file <_io.BytesIO object at 0x7f8863ed5fd0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image: path_to_destination/PetImages/Cat/Thumbs.db\n",
            "cannot identify image file <_io.BytesIO object at 0x7f885a795580>\n",
            "Error loading image: path_to_destination/PetImages/Cat/666.jpg\n",
            "cannot identify image file <_io.BytesIO object at 0x7f88617f5580>\n",
            "Found 24998 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXRFLk6ArbWw",
        "outputId": "34dcdf6d-3e15-4b2b-d5b5-ccf3fad3d5a8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m273/782\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 216ms/step - accuracy: 0.6555 - loss: 0.6193"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 339ms/step - accuracy: 0.6735 - loss: 0.6017 - val_accuracy: 0.7439 - val_loss: 0.5193\n",
            "Epoch 2/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 342ms/step - accuracy: 0.7472 - loss: 0.5147 - val_accuracy: 0.7724 - val_loss: 0.4796\n",
            "Epoch 3/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 340ms/step - accuracy: 0.7808 - loss: 0.4635 - val_accuracy: 0.7604 - val_loss: 0.4923\n",
            "Epoch 4/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 332ms/step - accuracy: 0.7937 - loss: 0.4445 - val_accuracy: 0.8047 - val_loss: 0.4196\n",
            "Epoch 5/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 331ms/step - accuracy: 0.8062 - loss: 0.4236 - val_accuracy: 0.8106 - val_loss: 0.4141\n",
            "Epoch 6/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 334ms/step - accuracy: 0.8163 - loss: 0.4045 - val_accuracy: 0.8251 - val_loss: 0.3840\n",
            "Epoch 7/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 344ms/step - accuracy: 0.8228 - loss: 0.3898 - val_accuracy: 0.8383 - val_loss: 0.3651\n",
            "Epoch 8/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 396ms/step - accuracy: 0.8292 - loss: 0.3785 - val_accuracy: 0.8234 - val_loss: 0.3829\n",
            "Epoch 9/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 334ms/step - accuracy: 0.8368 - loss: 0.3644 - val_accuracy: 0.8401 - val_loss: 0.3592\n",
            "Epoch 10/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 333ms/step - accuracy: 0.8440 - loss: 0.3486 - val_accuracy: 0.8123 - val_loss: 0.4014\n",
            "Epoch 11/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 334ms/step - accuracy: 0.8435 - loss: 0.3499 - val_accuracy: 0.8588 - val_loss: 0.3238\n",
            "Epoch 12/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 396ms/step - accuracy: 0.8538 - loss: 0.3332 - val_accuracy: 0.8659 - val_loss: 0.3071\n",
            "Epoch 13/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 331ms/step - accuracy: 0.8641 - loss: 0.3166 - val_accuracy: 0.8611 - val_loss: 0.3241\n",
            "Epoch 14/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 333ms/step - accuracy: 0.8637 - loss: 0.3155 - val_accuracy: 0.8791 - val_loss: 0.2887\n",
            "Epoch 15/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 395ms/step - accuracy: 0.8696 - loss: 0.3006 - val_accuracy: 0.8788 - val_loss: 0.2858\n",
            "Epoch 16/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 331ms/step - accuracy: 0.8765 - loss: 0.2847 - val_accuracy: 0.8786 - val_loss: 0.2873\n",
            "Epoch 17/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 396ms/step - accuracy: 0.8803 - loss: 0.2807 - val_accuracy: 0.8787 - val_loss: 0.2858\n",
            "Epoch 18/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 335ms/step - accuracy: 0.8854 - loss: 0.2753 - val_accuracy: 0.9014 - val_loss: 0.2401\n",
            "Epoch 19/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 394ms/step - accuracy: 0.8898 - loss: 0.2608 - val_accuracy: 0.8988 - val_loss: 0.2432\n",
            "Epoch 20/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 334ms/step - accuracy: 0.8922 - loss: 0.2560 - val_accuracy: 0.8852 - val_loss: 0.2698\n",
            "Epoch 21/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 338ms/step - accuracy: 0.8978 - loss: 0.2443 - val_accuracy: 0.8848 - val_loss: 0.2682\n",
            "Epoch 22/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 336ms/step - accuracy: 0.8997 - loss: 0.2420 - val_accuracy: 0.9102 - val_loss: 0.2191\n",
            "Epoch 23/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 337ms/step - accuracy: 0.9012 - loss: 0.2331 - val_accuracy: 0.9050 - val_loss: 0.2301\n",
            "Epoch 24/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 334ms/step - accuracy: 0.9076 - loss: 0.2251 - val_accuracy: 0.9119 - val_loss: 0.2150\n",
            "Epoch 25/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 337ms/step - accuracy: 0.9075 - loss: 0.2220 - val_accuracy: 0.9163 - val_loss: 0.2067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f8860eab290>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4- Making single Prediction"
      ],
      "metadata": {
        "id": "VabtXNbQryFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = tf.keras.utils.load_img(\n",
        "    r\"/content/path_to_destination/PetImages/Cat/10001.jpg\",\n",
        "    target_size=(64, 64)\n",
        ")\n",
        "test_image = tf.keras.utils.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "result = cnn.predict(test_image)\n",
        "print(training_set.class_indices)\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'"
      ],
      "metadata": {
        "id": "PhlVpKmur5dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fdf9d47-6159-457f-f6d4-755f0db576ee"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "{'Cat': 0, 'Dog': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d30SxxeXzPIJ",
        "outputId": "0bde10ad-b692-4f79-b82a-ea9879517f64"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n"
          ]
        }
      ]
    }
  ]
}